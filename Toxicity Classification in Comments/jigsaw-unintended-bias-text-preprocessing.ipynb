{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom nltk.corpus import stopwords\nfrom string import punctuation\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom keras.models import Sequential, Model\nfrom keras.utils import to_categorical,plot_model\nfrom keras.layers import Dense, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.initializers import he_normal\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.layers import Dropout\nfrom keras.layers import Embedding, LSTM, GRU, Flatten, Input, concatenate, Conv1D, GlobalMaxPool1D, SpatialDropout1D, GlobalMaxPooling1D, Bidirectional, GlobalAveragePooling1D, add\nfrom keras.regularizers import l2\nfrom keras.optimizers import Adam\nfrom keras.initializers import Orthogonal\nfrom keras.preprocessing.text import one_hot\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-28T23:17:23.446234Z","iopub.execute_input":"2021-06-28T23:17:23.446837Z","iopub.status.idle":"2021-06-28T23:17:32.286457Z","shell.execute_reply.started":"2021-06-28T23:17:23.446731Z","shell.execute_reply":"2021-06-28T23:17:32.285616Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv\n/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/all_data.csv\n/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test_public_expanded.csv\n/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test_private_expanded.csv\n/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/toxicity_individual_annotations.csv\n/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\n/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/identity_individual_annotations.csv\n/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\ntest_df = pd.read_csv('/kaggle/input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T23:17:35.050437Z","iopub.execute_input":"2021-06-28T23:17:35.051037Z","iopub.status.idle":"2021-06-28T23:18:02.430525Z","shell.execute_reply.started":"2021-06-28T23:17:35.050967Z","shell.execute_reply":"2021-06-28T23:18:02.429256Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T23:18:04.544582Z","iopub.execute_input":"2021-06-28T23:18:04.544982Z","iopub.status.idle":"2021-06-28T23:18:04.596867Z","shell.execute_reply.started":"2021-06-28T23:18:04.544949Z","shell.execute_reply":"2021-06-28T23:18:04.595823Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      id    target                                       comment_text  \\\n0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n1  59849  0.000000  Thank you!! This would make my life a lot less...   \n2  59852  0.000000  This is such an urgent design problem; kudos t...   \n3  59855  0.000000  Is this something I'll be able to install on m...   \n4  59856  0.893617               haha you guys are a bunch of losers.   \n\n   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n\n   ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n0  ...        2006  rejected      0    0    0      0         0   \n1  ...        2006  rejected      0    0    0      0         0   \n2  ...        2006  rejected      0    0    0      0         0   \n3  ...        2006  rejected      0    0    0      0         0   \n4  ...        2006  rejected      0    0    0      1         0   \n\n   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n0              0.0                         0                         4  \n1              0.0                         0                         4  \n2              0.0                         0                         4  \n3              0.0                         0                         4  \n4              0.0                         4                        47  \n\n[5 rows x 45 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n      <th>comment_text</th>\n      <th>severe_toxicity</th>\n      <th>obscene</th>\n      <th>identity_attack</th>\n      <th>insult</th>\n      <th>threat</th>\n      <th>asian</th>\n      <th>atheist</th>\n      <th>...</th>\n      <th>article_id</th>\n      <th>rating</th>\n      <th>funny</th>\n      <th>wow</th>\n      <th>sad</th>\n      <th>likes</th>\n      <th>disagree</th>\n      <th>sexual_explicit</th>\n      <th>identity_annotator_count</th>\n      <th>toxicity_annotator_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>59848</td>\n      <td>0.000000</td>\n      <td>This is so cool. It's like, 'would you want yo...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2006</td>\n      <td>rejected</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>59849</td>\n      <td>0.000000</td>\n      <td>Thank you!! This would make my life a lot less...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2006</td>\n      <td>rejected</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59852</td>\n      <td>0.000000</td>\n      <td>This is such an urgent design problem; kudos t...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2006</td>\n      <td>rejected</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>59855</td>\n      <td>0.000000</td>\n      <td>Is this something I'll be able to install on m...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2006</td>\n      <td>rejected</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59856</td>\n      <td>0.893617</td>\n      <td>haha you guys are a bunch of losers.</td>\n      <td>0.021277</td>\n      <td>0.0</td>\n      <td>0.021277</td>\n      <td>0.87234</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2006</td>\n      <td>rejected</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>47</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 45 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T23:18:06.976218Z","iopub.execute_input":"2021-06-28T23:18:06.976612Z","iopub.status.idle":"2021-06-28T23:18:06.999027Z","shell.execute_reply.started":"2021-06-28T23:18:06.976581Z","shell.execute_reply":"2021-06-28T23:18:06.997874Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1804874 entries, 0 to 1804873\nData columns (total 45 columns):\n #   Column                               Dtype  \n---  ------                               -----  \n 0   id                                   int64  \n 1   target                               float64\n 2   comment_text                         object \n 3   severe_toxicity                      float64\n 4   obscene                              float64\n 5   identity_attack                      float64\n 6   insult                               float64\n 7   threat                               float64\n 8   asian                                float64\n 9   atheist                              float64\n 10  bisexual                             float64\n 11  black                                float64\n 12  buddhist                             float64\n 13  christian                            float64\n 14  female                               float64\n 15  heterosexual                         float64\n 16  hindu                                float64\n 17  homosexual_gay_or_lesbian            float64\n 18  intellectual_or_learning_disability  float64\n 19  jewish                               float64\n 20  latino                               float64\n 21  male                                 float64\n 22  muslim                               float64\n 23  other_disability                     float64\n 24  other_gender                         float64\n 25  other_race_or_ethnicity              float64\n 26  other_religion                       float64\n 27  other_sexual_orientation             float64\n 28  physical_disability                  float64\n 29  psychiatric_or_mental_illness        float64\n 30  transgender                          float64\n 31  white                                float64\n 32  created_date                         object \n 33  publication_id                       int64  \n 34  parent_id                            float64\n 35  article_id                           int64  \n 36  rating                               object \n 37  funny                                int64  \n 38  wow                                  int64  \n 39  sad                                  int64  \n 40  likes                                int64  \n 41  disagree                             int64  \n 42  sexual_explicit                      float64\n 43  identity_annotator_count             int64  \n 44  toxicity_annotator_count             int64  \ndtypes: float64(32), int64(10), object(3)\nmemory usage: 619.7+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T23:18:07.696266Z","iopub.execute_input":"2021-06-28T23:18:07.697015Z","iopub.status.idle":"2021-06-28T23:18:07.703075Z","shell.execute_reply.started":"2021-06-28T23:18:07.696954Z","shell.execute_reply":"2021-06-28T23:18:07.701851Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(1804874, 45)\n(97320, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how does\",\n\"i'd\": \"i would\",\n\"i'd've\": \"i would have\",\n\"i'll\": \"i will\",\n\"i'll've\": \"i will have\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\" u \": \" you \",\n\" ur \": \" your \",\n\" n \": \" and \"}","metadata":{"execution":{"iopub.status.busy":"2021-06-28T23:29:37.868069Z","iopub.execute_input":"2021-06-28T23:29:37.868470Z","iopub.status.idle":"2021-06-28T23:29:37.881593Z","shell.execute_reply.started":"2021-06-28T23:29:37.868414Z","shell.execute_reply":"2021-06-28T23:29:37.880401Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def text_process(texts):\n    \n    corpus = []\n\n    for (idx, text) in enumerate(texts):\n    \n        text = text.lower()\n\n        for key in contractions:\n            value = contractions[key]\n            text = text.replace(key, value)\n\n        for punc in list(punctuation):\n            text = text.replace(punc, '')\n\n        text = text.split()\n\n        text = [word for word in text if word not in stopwords.words('english')]\n\n        text = ' '.join(text)\n        \n        corpus.append(text)\n    \n    return corpus","metadata":{"execution":{"iopub.status.busy":"2021-06-28T23:29:34.692164Z","iopub.execute_input":"2021-06-28T23:29:34.692591Z","iopub.status.idle":"2021-06-28T23:29:34.700490Z","shell.execute_reply.started":"2021-06-28T23:29:34.692556Z","shell.execute_reply":"2021-06-28T23:29:34.699378Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_df['comment_text'] = text_process(train_df.comment_text.values)\n# Wall Time 3hr 15 mins\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntest_df['comment_text'] = text_process(test_df.comment_text.values)\n#Wall time 11 mins","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv(\"test_clean_df2.csv\")\ntrain_df.to_csv(\"train_clean_df2.csv\")","metadata":{},"execution_count":null,"outputs":[]}]}
